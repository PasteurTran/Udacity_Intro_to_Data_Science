{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from ggplot import *\n",
    "\n",
    "\"\"\"\n",
    "In this question, you need to:\n",
    "1) implement the compute_cost() and gradient_descent() procedures\n",
    "2) Select features (in the predictions procedure) and make predictions.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def normalize_features(df):\n",
    "    \"\"\"\n",
    "    Normalize the features in the data set.\n",
    "    \"\"\"\n",
    "    mu = df.mean()\n",
    "    sigma = df.std()\n",
    "    \n",
    "    if (sigma == 0).any():\n",
    "        raise Exception(\"One or more features had the same value for all samples, and thus could \" + \\\n",
    "                         \"not be normalized. Please do not include features with only a single value \" + \\\n",
    "                         \"in your model.\")\n",
    "    df_normalized = (df - df.mean()) / df.std()\n",
    "\n",
    "    return df_normalized, mu, sigma\n",
    "\n",
    "def compute_cost(features, values, theta):\n",
    "    \"\"\"\n",
    "    Compute the cost function given a set of features / values, \n",
    "    and the values for our thetas.\n",
    "    \n",
    "    This can be the same code as the compute_cost function in the lesson #3 exercises,\n",
    "    but feel free to implement your own.\n",
    "    \"\"\"\n",
    "    \n",
    "    sum_of_square_errors = np.square(np.dot(features,theta)-values).sum()\n",
    "    cost = 1/(2*len(values))*sum_of_square_errors\n",
    "    \n",
    "\n",
    "    return cost\n",
    "\n",
    "def gradient_descent(features, values, theta, alpha, num_iterations):\n",
    "    \"\"\"\n",
    "    Perform gradient descent given a data set with an arbitrary number of features.\n",
    "    \n",
    "    This can be the same gradient descent code as in the lesson #3 exercises,\n",
    "    but feel free to implement your own.\n",
    "    \"\"\"\n",
    "    \n",
    "    m = len(values)\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        # Add cost history\n",
    "        cost_history.append(compute_cost(features, values, theta))\n",
    "        \n",
    "        #Calculate hypothesis\n",
    "        hypothesis = np.dot(features, theta)\n",
    "        loss = hypothesis - values\n",
    "        gradient = np.dot(features.transpose(), loss) / m\n",
    "        theta = theta - alpha * gradient\n",
    "        \n",
    "    return theta, pandas.Series(cost_history)\n",
    "\n",
    "def predictions(dataframe):\n",
    "    '''\n",
    "    The NYC turnstile data is stored in a pandas dataframe called weather_turnstile.\n",
    "    Using the information stored in the dataframe, let's predict the ridership of\n",
    "    the NYC subway using linear regression with gradient descent.\n",
    "    \n",
    "    You can download the complete turnstile weather dataframe here:\n",
    "    https://www.dropbox.com/s/meyki2wl9xfa7yk/turnstile_data_master_with_weather.csv    \n",
    "    \n",
    "    Your prediction should have a R^2 value of 0.40 or better.\n",
    "    You need to experiment using various input features contained in the dataframe. \n",
    "    We recommend that you don't use the EXITSn_hourly feature as an input to the \n",
    "    linear model because we cannot use it as a predictor: we cannot use exits \n",
    "    counts as a way to predict entry counts. \n",
    "    \n",
    "    Note: Due to the memory and CPU limitation of our Amazon EC2 instance, we will\n",
    "    give you a random subet (~15%) of the data contained in \n",
    "    turnstile_data_master_with_weather.csv. You are encouraged to experiment with \n",
    "    this computer on your own computer, locally. \n",
    "    \n",
    "    \n",
    "    If you'd like to view a plot of your cost history, uncomment the call to \n",
    "    plot_cost_history below. The slowdown from plotting is significant, so if you \n",
    "    are timing out, the first thing to do is to comment out the plot command again.\n",
    "    \n",
    "    If you receive a \"server has encountered an error\" message, that means you are \n",
    "    hitting the 30-second limit that's placed on running your program. Try using a \n",
    "    smaller number for num_iterations if that's the case.\n",
    "    \n",
    "    If you are using your own algorithm/models, see if you can optimize your code so \n",
    "    that it runs faster.\n",
    "    '''\n",
    "    # Select Features (try different features!)\n",
    "    features = dataframe[['rain', 'precipi', 'Hour', 'meantempi']]\n",
    "    \n",
    "    # Add UNIT to features using dummy variables\n",
    "    dummy_units = pandas.get_dummies(dataframe['UNIT'], prefix='unit')\n",
    "    features = features.join(dummy_units)\n",
    "    \n",
    "    # Values\n",
    "    values = dataframe['ENTRIESn_hourly']\n",
    "    m = len(values)\n",
    "\n",
    "    features, mu, sigma = normalize_features(features)\n",
    "    features['ones'] = np.ones(m) # Add a column of 1s (y intercept)\n",
    "    \n",
    "    # Convert features and values to numpy arrays\n",
    "    features_array = np.array(features)\n",
    "    values_array = np.array(values)\n",
    "\n",
    "    # Set values for alpha, number of iterations.\n",
    "    alpha = 0.1 # please feel free to change this value\n",
    "    num_iterations = 75 # please feel free to change this value\n",
    "\n",
    "    # Initialize theta, perform gradient descent\n",
    "    theta_gradient_descent = np.zeros(len(features.columns))\n",
    "    theta_gradient_descent, cost_history = gradient_descent(features_array, \n",
    "                                                            values_array, \n",
    "                                                            theta_gradient_descent, \n",
    "                                                            alpha, \n",
    "                                                            num_iterations)\n",
    "    \n",
    "    plot = None\n",
    "    # -------------------------------------------------\n",
    "    # Uncomment the next line to see your cost history\n",
    "    # -------------------------------------------------\n",
    "    # plot = plot_cost_history(alpha, cost_history)\n",
    "    # \n",
    "    # Please note, there is a possibility that plotting\n",
    "    # this in addition to your calculation will exceed \n",
    "    # the 30 second limit on the compute servers.\n",
    "    \n",
    "    predictions = np.dot(features_array, theta_gradient_descent)\n",
    "    return predictions, plot\n",
    "\n",
    "\n",
    "def plot_cost_history(alpha, cost_history):\n",
    "   \"\"\"This function is for viewing the plot of your cost history.\n",
    "   You can run it by uncommenting this\n",
    "\n",
    "       plot_cost_history(alpha, cost_history) \n",
    "\n",
    "   call in predictions.\n",
    "   \n",
    "   If you want to run this locally, you should print the return value\n",
    "   from this function.\n",
    "   \"\"\"\n",
    "   cost_df = pandas.DataFrame({\n",
    "      'Cost_History': cost_history,\n",
    "      'Iteration': range(len(cost_history))\n",
    "   })\n",
    "   return ggplot(cost_df, aes('Iteration', 'Cost_History')) + \\\n",
    "      geom_point() + ggtitle('Cost History for alpha = %.3f' % alpha )\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
